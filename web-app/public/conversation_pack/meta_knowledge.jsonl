{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — header] Session-ID: S-2026-02-10-1000-four-lane-rag\nTitle: Four-Lane RAG Pipeline Refactor\nDate: 2026-02-10\nAuthor: dmar"}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-goal-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","persona"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Goal] Replace single-index retrieval with a multi-lane pipeline (persona, playbook, knowledge, lore) that gives the Iris Kade character distinct behavioral modes."}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-context-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","persona"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Context] The original RAG system was a flat vector search — every query hit every chunk with identical treatment. Iris needed structured behavior: identity responses for \"who are you?\", playbook-driven greetings, knowledge retrieval for factual questions, and lore for flavor text."}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-plan-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","llm","persona"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Plan] 1. Define lane types in `types.ts`: persona, playbook, knowledge, lore\n2. Build `stateGate.ts` to classify intent and select lanes per turn\n3. Build `retrieve.ts` with dual-index (style vs knowledge)\n4. Build `rerank.ts` with weighted scoring (vector + lexical + metadata + intent - repeat)\n5. Build `compose.ts` with pack-only and LLM-enhanced paths\n6. Build `memory.ts` for anti-repeat window\n7. Build `pipeline.ts` as orchestrator\n8. Wire into `main.ts`"}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-changes-made-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","llm","persona"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Changes Made] - Created `web-app/src/lib/conversationPack/` directory with 8 files\n- `types.ts`: PackItem, Persona, PlaybookEntry, KnowledgeNugget, LoreLine, ConversationState, RetrievalCandidate, ComposeResult\n- `stateGate.ts`: keyword-based intent/tone/route classification (<1ms)\n- `retrieve.ts`: dual-index retrieval with soft intent scoring\n- `rerank.ts`: weighted scoring with anti-repeat penalties\n- `compose.ts`: pack-only + LLM-enhanced composition\n- `memory.ts`: 20-item window with linear decay\n- `packIndex.ts`: JSONL parsing, pack loading, embedding attachment\n- `lexical.ts`: tokenizer + slang-boosted lexical scoring\n- `pipeline.ts`: full orchestrator wiring all stages"}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-decisions-made-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","llm","persona"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Decisions Made] - **4 lanes instead of 1**: Persona/playbook are deterministic, knowledge/lore use retrieval. See ADR-001.\n- **Soft intent scoring**: No hard filters — all items are candidates, but intent mismatch costs points.\n- **20-item anti-repeat**: Hard exclude last 3 turns, soft penalty within window.\n- **Pack-only fallback**: System works without LLM loaded."}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-open-questions-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","llm"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Open Questions] - Should playbook entries be embedded too, or is keyword matching sufficient?\n- LLM prompt may cause parroting of RAG context (addressed in later session)."}
{"id":"meta-session-s-2026-02-10-1000-four-lane-rag-links-7","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[S-2026-02-10-1000-four-lane-rag — Links] - ADR-001-four-lane-rag.md"}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — header] Session-ID: S-2026-02-10-1600-bug-fixes-round2\nTitle: Bug Fixes Round 2 — Greeting, Dialogue Dump, Length Budget\nDate: 2026-02-10\nAuthor: dmar"}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-goal-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","testing"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — Goal] Fix three behavioral bugs observed during testing: broken greeting detection, dialogue dump in responses, and length budget violations."}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-context-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","testing"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — Context] After the four-lane RAG refactor, testing revealed:\n1. Greeting detection missed common patterns (\"hey\", \"yo\", \"what's up\")\n2. Dialogue-type pack items were being dumped verbatim into responses\n3. Length budget was being ignored — short queries got paragraph-length replies"}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-changes-made-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — Changes Made] - Expanded greeting patterns in `stateGate.ts`\n- Added dialogue-type filtering in `compose.ts` to extract only relevant lines\n- Wired length budget from state gate into compose constraints"}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-decisions-made-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — Decisions Made] - Greetings use exact-match patterns, not fuzzy matching (faster, more predictable)\n- Dialogue items use `structure_only` usage — content is paraphrased, never copied\n- Length budget maps: 1line=1 sentence, short=2-3 sentences, medium=4-6 sentences"}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-open-questions-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — Open Questions] - None remaining from this round"}
{"id":"meta-session-s-2026-02-10-1600-bug-fixes-round2-links-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[S-2026-02-10-1600-bug-fixes-round2 — Links] - S-2026-02-10-1000-four-lane-rag.md (parent session)"}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — header] Session-ID: S-2026-02-11-1000-prompt-contract\nTitle: LLM Prompt Contract — Memory Notes Framing\nDate: 2026-02-11\nAuthor: dmar"}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-goal-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","llm"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Goal] Fix LLM parroting of RAG context by rewriting the system prompt to frame retrieval results as optional background rather than instructions."}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-context-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Context] When the LLM received context snippets labeled \"Reference snippets\", it would copy them nearly verbatim. The model treated the snippets as authoritative text to reproduce rather than background to draw from."}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-plan-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","llm"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Plan] 1. Rename \"Reference snippets\" to \"Memory notes (optional background)\"\n2. Add explicit RAG rules to system prompt\n3. Instruct model to: answer in own words, treat notes as optional, ignore irrelevant notes, prefer short replies, ask clarifying questions"}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-changes-made-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","llm","persona"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Changes Made] - `llm.ts`: Added RAG rules section to IRIS_SYSTEM_PROMPT\n- `llm.ts`: Changed context label from \"Reference snippets\" to \"Memory notes (optional background — use only if relevant, never copy verbatim)\""}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-decisions-made-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","persona"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Decisions Made] - **\"Memory notes\" framing**: Makes retrieval feel like the character's memory, not instructions. See ADR-002.\n- **Explicit anti-copy rule**: \"never copy verbatim\" in both system prompt and context label.\n- **Clarify-over-guess**: When unsure, Iris asks a question instead of hallucinating."}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-open-questions-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Open Questions] - Should temperature be raised to further reduce verbatim copying?\n- Could few-shot examples in the system prompt help?"}
{"id":"meta-session-s-2026-02-11-1000-prompt-contract-links-7","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[S-2026-02-11-1000-prompt-contract — Links] - ADR-002-prompt-contract.md"}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts","behavior"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — header] Session-ID: S-2026-02-11-1400-fsm-streaming-tts\nTitle: FSM Turn Management + Streaming TTS + Adaptive Bias\nDate: 2026-02-11\nAuthor: dmar"}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-goal-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts","behavior"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Goal] Replace the boolean `processing` flag with a proper FSM, add streaming sentence-level TTS (hear first sentence before full response), support mid-response interruption, and add adaptive conversation bias."}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-context-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts","stt","behavior","persona"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Context] The Iris Kade pipeline had solid 4-lane RAG but a naive interaction loop: boolean `processing` flag silently dropped input during processing/speaking, TTS waited for complete reply, no interruption handling, no adaptive behavior. Patterns borrowed from browser-voice-agent-with-TTS-STT demo."}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-plan-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","tts","behavior"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Plan] - Phase 0: Session tracing framework (templates, scripts, retroactive sessions, ADRs, pre-commit hook)\n- Phase 1: SentenceBuffer (token accumulator) + SentenceSpeaker (concurrent generate+playback)\n- Phase 2: FSM (IDLE/PROCESSING/SPEAKING/INTERRUPTED) + turn queue + AbortController\n- Phase 3: ConversationBias (verbosity/depth/warmth 0-1 with decay)\n- Phase 4: Filler speech, interruption UX, debug panel enhancements"}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-changes-made-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","tts","llm","testing","behavior"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Changes Made] ### New files\n- `web-app/src/lib/sentenceBuffer.ts` — Accumulates streaming tokens, emits sentences at `.!?` boundaries, handles abbreviations and ellipsis\n- `web-app/src/lib/conversationFSM.ts` — 4-state FSM with typed event system, 1-slot turn queue (newest-wins, 8s staleness), AbortController per turn, SentenceBuffer+SentenceSpeaker integration, filler speech on >500ms delay\n- `web-app/src/lib/bias.ts` — 3-parameter adaptive bias (verbosity→max_tokens, depth→lane selection, warmth→tone), decay 10% toward 0.5 each turn\n- `docs/project-memory/` — Full session tracing framework with templates, 3 retroactive sessions, 3 ADRs\n- `scripts/build-index.sh` — Bash 3-compatible keyword index builder\n- `scripts/setup-hooks.sh` — Pre-commit hook installer\n- `scripts/test.sh` — Framework verification\n\n### Modified files\n- `web-app/src/lib/tts.ts` — Added SentenceSpeaker class (concurrent TTS generation + playback, max 2 ahead backpressure, abort support)\n- `web-app/src/lib/llm.ts` — Added AbortSignal + maxTokens options to generateReply()\n- `web-app/src/lib/conversationPack/pipeline.ts` — Pass-through signal + maxTokens to composeLLM\n- `web-app/src/main.ts` — Replaced `handleUserInput` + `processing` boolean with FSM wiring, added bias/FSM state/queue depth to debug panel, escapeHtml on all dynamic values in debug renderer"}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-decisions-made-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","tts","behavior","persona"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Decisions Made] - **FSM over boolean**: 4 states enable distinct interrupt behavior per state. See ADR-003.\n- **SentenceSpeaker backpressure**: Max 2 sentences pre-generated to prevent memory bloat.\n- **Bias in FSM, not pipeline**: FSM observes turns and passes `maxTokens` to pipeline. Keeps pipeline simpler.\n- **Filler speech**: Random Iris-character filler plays after 500ms if no sentence yet.\n- **Newest-wins queue**: 1-slot, not FIFO. If user sends 3 messages fast, only the last processes."}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-open-questions-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","tts","llm","testing","architecture","behavior"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Open Questions] - Should filler speech be configurable?\n- Should bias.depth actually influence lane selection in the pipeline, or is max_tokens sufficient?\n- Test with actual LLM loaded to verify abort propagation through web-llm streaming"}
{"id":"meta-session-s-2026-02-11-1400-fsm-streaming-tts-links-7","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[S-2026-02-11-1400-fsm-streaming-tts — Links] - ADR-003-fsm-turn-management.md\n- S-2026-02-11-1000-prompt-contract.md (previous session)"}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — header] Session-ID: S-2026-02-12-1000-model-testing-framework\nTitle: Automated Model Testing + Self-Referential Meta-Knowledge\nDate: 2026-02-12\nAuthor: dmar"}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-goal-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing","persona"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Goal] Build automated Playwright tests to evaluate each of the 17 available LLM models against standard prompts, generate comparison reports, and add self-referential meta-knowledge so Iris can answer questions about her own architecture and recent changes."}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-context-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","tts","llm","behavior","persona"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Context] The pipeline has 4-lane RAG, FSM turn management, streaming TTS, adaptive bias, and LLM integration with 17 models. Problem: no systematic way to evaluate which models work well, compare results across models, or have Iris talk about her own architecture. Session tracing infrastructure already exists (docs/project-memory/ with 4 sessions + 3 ADRs)."}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-plan-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","llm","testing","architecture"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Plan] - Phase 1: Playwright model testing framework (config, test prompts, model comparison spec, pack-only baseline, report generator)\n- Phase 2: Session doc + ADR for this work (this document)\n- Phase 3: Self-referential meta-knowledge (session-to-JSONL indexer, meta routing in stateGate, pipeline integration)"}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-changes-made-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","llm","testing","architecture"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Changes Made] ### New files\n- `web-app/playwright.config.ts` — Chromium with WebGPU flags, 10min timeout, serial execution, auto-start Vite dev server\n- `web-app/tests/test-prompts.json` — 12 standard prompts covering greeting, identity, vent, boundary, knowledge, decision, brainstorm, meta, followup\n- `web-app/tests/model-comparison.spec.ts` — Loads each model, runs all prompts, captures responses + latency + debug info, saves JSON + screenshots\n- `web-app/tests/pack-only-baseline.spec.ts` — Pack-only baseline (no LLM), validates all 12 prompts get responses, completes in <30s\n- `web-app/scripts/generate-report.ts` — Reads JSON results, generates comparison.md with summary table + per-prompt comparison\n- `scripts/index-sessions.ts` — Reads session docs + ADRs, chunks by heading, outputs JSONL matching PackItem format\n- `docs/project-memory/adr/ADR-004-playwright-model-testing.md` — ADR for Playwright testing approach\n\n### Modified files\n- `web-app/package.json` — Added @playwright/test, test:models, test:baseline, test:report, index-meta scripts\n- `.gitignore` — Added web-app/test-results/\n- `web-app/src/lib/conversationPack/stateGate.ts` — Added META_KNOWLEDGE_PATTERNS for self-referential routing\n- `web-app/src/lib/conversationPack/types.ts` — Added 'meta' to SpecialRoute union\n- `web-app/src/lib/conversationPack/pipeline.ts` — Load + merge meta_knowledge.jsonl at init"}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-decisions-made-part-1-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Decisions Made (part 1)] - **Playwright over Puppeteer**: Playwright has built-in WebGPU support via Chromium flags, better test runner, and auto-server management. - **Serial execution**: WebGPU contexts compete for GPU memory — only one model can be loaded at a time. - **Pack-only baseline as separate test**: Fast feedback loop (<30s) vs model tests (minutes each). - **JSON + Markdown reporting**: JSON for programmatic comparison, Markdown for human reading. - **ESM import attributes**: Node.js ESM requires `with { type: 'json' }` for JSON imports — Playwright tests run in Node, not Vite."}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-decisions-made-part-2-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Decisions Made (part 2)] - **Meta-knowledge as PackItems**: Reuses existing retrieval/reranking infrastructure instead of a separate system."}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-open-questions-7","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Open Questions] - Should model comparison run in CI? WebGPU availability on CI runners is limited.\n- Should we add response quality scoring (beyond latency and LLM usage rate)?\n- How frequently should meta_knowledge.jsonl be regenerated?"}
{"id":"meta-session-s-2026-02-12-1000-model-testing-framewor-links-8","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts","llm","testing"],"usage":"paraphrase","text":"[S-2026-02-12-1000-model-testing-framework — Links] - ADR-004-playwright-model-testing.md\n- S-2026-02-11-1400-fsm-streaming-tts.md (previous session)"}
{"id":"meta-adr-adr-001-four-lane-rag-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — header] # ADR-001: Four-Lane RAG Architecture"}
{"id":"meta-adr-adr-001-four-lane-rag-context-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","persona"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — Context] The Iris Kade character requires distinct behavioral modes: identity responses, social greetings, factual knowledge retrieval, and flavor text. A single flat vector index treats all content identically — \"who are you?\" retrieves the same way as \"explain zero-day exploits.\""}
{"id":"meta-adr-adr-001-four-lane-rag-decision-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","persona"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — Decision] Split retrieval into 4 lanes:\n- **Persona**: Direct inject, no retrieval (identity questions)\n- **Playbook**: Pattern-matched social behaviors (greetings, echoes, clarifications)\n- **Knowledge**: Vector + lexical retrieval for factual content\n- **Lore**: Flavor text retrieval for character depth\n\nA state gate (`stateGate.ts`) classifies each turn's intent and selects active lanes before any retrieval happens."}
{"id":"meta-adr-adr-001-four-lane-rag-consequences-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","testing","persona"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — Consequences] **Easier:**\n- Each lane has tuned behavior — greetings are instant, knowledge gets full retrieval\n- Persona responses never accidentally mix with knowledge\n- Anti-repeat works per-lane\n\n**Harder:**\n- More code to maintain (8 files in conversationPack/)\n- State gate is keyword-based — may misclassify novel inputs\n- Testing requires coverage across all 4 lanes"}
{"id":"meta-adr-adr-001-four-lane-rag-evidence-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","llm","persona"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — Evidence] - Persona direct-inject: <1ms response time for \"who are you?\"\n- Playbook pattern matching: <2ms for greetings\n- Full knowledge retrieval: ~20ms (embed + search + rerank)\n- Pack-only mode (no LLM): all responses <50ms"}
{"id":"meta-adr-adr-001-four-lane-rag-sessions-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — Sessions] - S-2026-02-10-1000-four-lane-rag.md"}
{"id":"meta-adr-adr-001-four-lane-rag-commits-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[ADR-001-four-lane-rag — Commits] - Initial implementation in conversationPack/ directory"}
{"id":"meta-adr-adr-002-prompt-contract-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — header] # ADR-002: Memory Notes Prompt Framing"}
{"id":"meta-adr-adr-002-prompt-contract-context-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts","llm","persona"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — Context] When LLM receives RAG context labeled \"Reference snippets,\" it copies them verbatim. The model treats retrieved text as authoritative content to reproduce, not background to draw from. This defeats the purpose of having a character voice."}
{"id":"meta-adr-adr-002-prompt-contract-decision-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — Decision] 1. Rename context label from \"Reference snippets\" to \"Memory notes (optional background)\"\n2. Add explicit RAG rules to system prompt:\n   - Answer in own words\n   - Treat notes as optional memory, not instructions\n   - Ignore irrelevant notes completely\n   - Prefer short conversational replies\n   - Ask clarifying questions when unsure\n3. Include anti-copy directive in context label itself: \"never copy verbatim\""}
{"id":"meta-adr-adr-002-prompt-contract-consequences-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","tts","llm","testing","persona"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — Consequences] **Easier:**\n- Character voice maintained even with heavy RAG context\n- Short, natural replies instead of information dumps\n- Graceful handling of irrelevant retrieval results\n\n**Harder:**\n- Model may occasionally ignore relevant context\n- Prompt engineering is fragile — different models may need different framing\n- No automated test for \"verbatim copying\" detection"}
{"id":"meta-adr-adr-002-prompt-contract-evidence-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","llm"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — Evidence] - Before: Model copied 60-80% of retrieved text verbatim\n- After: Model paraphrases and integrates naturally, <10% overlap with source"}
{"id":"meta-adr-adr-002-prompt-contract-sessions-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — Sessions] - S-2026-02-11-1000-prompt-contract.md"}
{"id":"meta-adr-adr-002-prompt-contract-commits-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm"],"usage":"paraphrase","text":"[ADR-002-prompt-contract — Commits] - System prompt rewrite in llm.ts"}
{"id":"meta-adr-adr-003-fsm-turn-management-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — header] # ADR-003: FSM Turn Management"}
{"id":"meta-adr-adr-003-fsm-turn-management-context-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","tts","llm","behavior"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — Context] The interaction loop uses a boolean `processing` flag (`main.ts:298`). New input while processing or speaking is silently dropped. There's no way to interrupt mid-response, no streaming TTS, and no adaptive behavior. With LLM mode, users stare at \"...\" for seconds before hearing anything."}
{"id":"meta-adr-adr-003-fsm-turn-management-decision-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","tts","llm"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — Decision] Replace the boolean flag with a 4-state finite state machine:\n- **IDLE**: Waiting for input\n- **PROCESSING**: Pipeline running (LLM generating)\n- **SPEAKING**: TTS playing sentences\n- **INTERRUPTED**: Canceling current turn, preparing to process queued input\n\nKey behaviors:\n- 1-slot turn queue (newest-wins) — input during PROCESSING or SPEAKING replaces queued input\n- AbortController per turn — interruption cancels LLM and TTS\n- SentenceBuffer accumulates streaming tokens, emits complete sentences\n- SentenceSpeaker plays sentences concurrently with generation (sentence N plays while N+1 generates)"}
{"id":"meta-adr-adr-003-fsm-turn-management-consequences-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","llm","architecture"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — Consequences] **Easier:**\n- Users hear first sentence before full response is generated\n- Mid-response interruption feels natural\n- Turn queue prevents input loss\n\n**Harder:**\n- More complex state management (4 states vs 1 boolean)\n- AbortController wiring through pipeline + LLM\n- Edge cases: rapid input, stale queue, partial responses"}
{"id":"meta-adr-adr-003-fsm-turn-management-evidence-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts","stt"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — Evidence] - Pattern borrowed from browser-voice-agent-with-TTS-STT demo (8-stage FSM)\n- Simplified to 4 states for this use case"}
{"id":"meta-adr-adr-003-fsm-turn-management-sessions-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","architecture","tts"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — Sessions] - S-2026-02-11-1400-fsm-streaming-tts.md (created during implementation)"}
{"id":"meta-adr-adr-003-fsm-turn-management-commits-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta"],"usage":"paraphrase","text":"[ADR-003-fsm-turn-management — Commits] - (to be linked during implementation)"}
{"id":"meta-adr-adr-004-playwright-model-testing-header-0","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — header] # ADR-004: Playwright for Automated Model Testing"}
{"id":"meta-adr-adr-004-playwright-model-testing-context-1","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","architecture","llm","testing","persona"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Context] The Iris Kade pipeline supports 17 WebGPU LLM models via @mlc-ai/web-llm. Until now, model evaluation was manual: load a model, type prompts, subjectively judge quality. No systematic comparison of response quality, latency, or LLM utilization rate existed across models.\n\nWe need automated browser-based testing because:\n- Models run in-browser via WebGPU (can't test with Node.js alone)\n- The full pipeline (RAG retrieval → reranking → LLM compose) must be exercised\n- Results must be comparable across models with identical prompts"}
{"id":"meta-adr-adr-004-playwright-model-testing-decision-part-1-2","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Decision (part 1)] Use Playwright Test as the automated model testing framework with:\n\n1. **Chromium + WebGPU flags**: `--enable-unsafe-webgpu`, `--use-vulkan=swiftshader` for software-rendered WebGPU in headless mode\n2. **Serial execution**: One worker, one model at a time (WebGPU contexts compete for GPU memory)\n3. **10-minute timeout per test**: Model loading from cache/network can be slow\n4. **Standard prompt set**: 12 prompts covering all intent categories (greeting, identity, vent, boundary, knowledge, decision, brainstorm, meta, followup, smalltalk)\n5."}
{"id":"meta-adr-adr-004-playwright-model-testing-decision-part-2-3","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Decision (part 2)] **Dual test strategy**: Fast pack-only baseline (<30s) + slow model comparison (minutes per model)\n6. **JSON + Markdown reporting**: Per-model JSON for programmatic analysis, comparison.md for human review"}
{"id":"meta-adr-adr-004-playwright-model-testing-consequences-4","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"medium","domain":["meta","llm","testing","architecture"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Consequences] **Easier:**\n- Systematic model evaluation with consistent prompts\n- Regression testing when pipeline changes affect response quality\n- Objective latency comparison across models\n- Screenshots at each step for visual verification\n\n**Harder:**\n- CI integration (WebGPU not available on most CI runners)\n- Full model set testing is slow (~5-10 min per model)\n- Results depend on hardware (GPU vs swiftshader performance differs)"}
{"id":"meta-adr-adr-004-playwright-model-testing-evidence-5","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Evidence] - Pack-only baseline test completes in <30s, all 12 prompts get responses\n- Playwright WebGPU flags work with Chromium's swiftshader backend\n- `test.describe.serial` ensures one model at a time"}
{"id":"meta-adr-adr-004-playwright-model-testing-sessions-6","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Sessions] - S-2026-02-12-1000-model-testing-framework.md"}
{"id":"meta-adr-adr-004-playwright-model-testing-commits-7","kind":"explanation","intent":["question"],"tone":["noir-dry","calm"],"length":"short","domain":["meta","llm","testing"],"usage":"paraphrase","text":"[ADR-004-playwright-model-testing — Commits] - d53a533 Add Playwright model comparison test framework"}
